import streamlit as st
import requests
import json
import os
import re
import whisper
import base64
import zlib
from datetime import datetime

# å…¼å®¹ dotenv
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

# ===================== 1. åŸºç¡€é…ç½® =====================
st.set_page_config(page_title="é£ä¹¦åŸç”Ÿçºªè¦ï¼šå›¾æ–‡æ¶æ„ç‰ˆ", page_icon="ğŸ“ˆ", layout="wide")

APP_ID = "cli_a916f070b0f8dcd6"
APP_SECRET = "gHOYZxXsoTXpmsnyf37C5dqcN4tOkibW"
QWEN_API_KEY = "sk-ecb46034c430477e9c9a4b4fd6589742"

# ===================== 2. é£ä¹¦æ ¸å¿ƒ API å¼•æ“ =====================

def get_feishu_token():
    try:
        url = "https://open.feishu.cn/open-apis/auth/v3/tenant_access_token/internal"
        res = requests.post(url, json={"app_id": APP_ID, "app_secret": APP_SECRET}, timeout=10)
        return res.json().get("tenant_access_token")
    except:
        return None

def create_feishu_doc(title):
    token = get_feishu_token()
    if not token: return None
    url = "https://open.feishu.cn/open-apis/docx/v1/documents"
    headers = {"Authorization": f"Bearer {token}", "Content-Type": "application/json"}
    safe_title = str(title).strip() if title else "æ™ºèƒ½å›¾æ–‡çºªè¦"
    res = requests.post(url, headers=headers, json={"title": safe_title})
    return res.json().get("data", {}).get("document", {}).get("document_id")

def upload_diagram_to_feishu(doc_id, mermaid_code):
    """ã€æ ¸å¿ƒä¿®å¤ã€‘å°† Mermaid ä»£ç æ¸²æŸ“æˆå›¾ç‰‡å¹¶æºå¸¦ doc_id ä¸Šä¼ è‡³é£ä¹¦"""
    token = get_feishu_token()
    if not token or not mermaid_code or len(mermaid_code) < 10: return None
    
    try:
        # æ¸…æ´— LLM è¾“å‡ºçš„æ¢è¡Œç¬¦å’Œä»£ç å—æ ‡è®°
        clean_code = mermaid_code.replace("```mermaid", "").replace("```", "").strip()
        clean_code = clean_code.replace('\\n', '\n') # å¼ºåˆ¶è½¬æ¢å¯èƒ½è¢«è½¬ä¹‰çš„æ¢è¡Œç¬¦
        
        # å‹ç¼©å¹¶ç¼–ç ï¼Œè¯·æ±‚ Kroki æ¸²æŸ“æ¥å£
        compressed = zlib.compress(clean_code.encode('utf-8'), 9)
        encoded = base64.urlsafe_b64encode(compressed).decode('ascii')
        img_url = f"https://kroki.io/mermaid/png/{encoded}"
        
        img_res = requests.get(img_url, timeout=20)
        if img_res.status_code != 200: 
            st.warning(f"âš ï¸ å›¾å½¢æ¸²æŸ“æœåŠ¡å™¨æŠ¥é”™ (ä»£ç å¯èƒ½æœ‰è¯­æ³•é”™è¯¯): {img_res.text}")
            return None
            
        img_bytes = img_res.content

        # è°ƒç”¨é£ä¹¦ä¸Šä¼  API
        upload_url = "https://open.feishu.cn/open-apis/drive/v1/medias/upload_all"
        headers = {"Authorization": f"Bearer {token}"}
        
        # ã€è‡´èƒœä¿®å¤ã€‘ï¼šæ–°å¢ parent_node å‚æ•°ï¼Œé£ä¹¦æ‰ä¼šå…è®¸æ’å…¥è¯¥æ–‡æ¡£
        data = {
            "file_name": "diagram.png", 
            "parent_type": "docx_image", 
            "parent_node": doc_id, 
            "size": len(img_bytes)
        }
        files = {"file": ("diagram.png", img_bytes, "image/png")}
        
        up_res = requests.post(upload_url, headers=headers, data=data, files=files, timeout=15)
        up_data = up_res.json()
        
        if up_data.get("code") != 0:
            st.warning(f"âš ï¸ é£ä¹¦åª’ä½“æ¥æ”¶å¤±è´¥: {up_data}")
            return None
            
        return up_data.get("data", {}).get("file_token")
    except Exception as e:
        st.warning(f"âš ï¸ å›¾è¡¨æ„å»ºè¿‡ç¨‹ä¸­æ–­: {e}")
        return None

# ===================== 3. é€šç”¨ä¸‡èƒ½æ’ç‰ˆä¸å®‰å…¨æ„å»ºå™¨ =====================

def safe_text(content):
    return str(content).replace('\n', ' ').strip() or " "

def empty_line():
    return {"block_type": 2, "text": {"elements": [{"text_run": {"content": " "}}]}}

def build_universal_blocks(data, diagram_file_token=None):
    blocks = []

    # 1. å…ƒæ•°æ®
    meta = data.get("meta", {})
    blocks.append({"block_type": 3, "heading1": {"elements": [{"text_run": {"content": safe_text(meta.get('theme', 'æ™ºèƒ½çºªè¦'))}}]}})
    blocks.append({"block_type": 2, "text": {"elements": [{"text_run": {"content": f"ğŸ“… {safe_text(meta.get('time', 'è¿‘æœŸ'))}  |  ğŸ‘¥ {safe_text(meta.get('participants', 'ä¸ä¼šäººå‘˜'))}", "text_element_style": {"text_color": 7}}}]}})
    blocks.append(empty_line())

    # 2. ä¸€åˆ†é’Ÿé€Ÿè¯»
    summary = data.get("quick_summary", [])
    if summary:
        blocks.append({"block_type": 4, "heading2": {"elements": [{"text_run": {"content": "ğŸ’¡ æ ¸å¿ƒå…±è¯†"}}]}})
        for point in summary:
            blocks.append({
                "block_type": 2,
                "text": {"elements": [{"text_run": {"content": f" {safe_text(point)} ", "text_element_style": {"background_color": 5, "bold": True}}}]}
            })
        blocks.append(empty_line())

    # 3. æ¶æ„å›¾ (Image Block)
    if diagram_file_token:
        blocks.append({"block_type": 4, "heading2": {"elements": [{"text_run": {"content": "ğŸ“Š ä¼šè®®é€»è¾‘æ¶æ„å›¾"}}]}})
        blocks.append({"block_type": 27, "image": {"token": diagram_file_token}})
        blocks.append(empty_line())

    # 4. è®®é¢˜ä¸‹é’»
    topics = data.get("topics", [])
    if topics:
        blocks.append({"block_type": 4, "heading2": {"elements": [{"text_run": {"content": "ğŸ“ æ ¸å¿ƒè®®é¢˜è¯¦è¿°"}}]}})
        for idx, topic in enumerate(topics):
            blocks.append({"block_type": 5, "heading3": {"elements": [{"text_run": {"content": f"{idx+1}. {safe_text(topic.get('title'))}", "text_element_style": {"text_color": 5}}}]}})
            for detail in topic.get("details", []):
                blocks.append({"block_type": 12, "bullet": {"elements": [{"text_run": {"content": safe_text(detail)}}]}})
            conclusion = safe_text(topic.get("conclusion", ""))
            if conclusion and conclusion != " ":
                blocks.append({"block_type": 2, "text": {"elements": [{"text_run": {"content": f" â” ç»“è®º: {conclusion} ", "text_element_style": {"bold": True, "text_color": 4}}}]}})
            blocks.append(empty_line())

    # 5. å¾…åŠ (Checkbox)
    todos = data.get("todos", [])
    if todos:
        blocks.append({"block_type": 4, "heading2": {"elements": [{"text_run": {"content": "âœ… è¡ŒåŠ¨ä¸å¾…åŠ"}}]}})
        for todo in todos:
            task = safe_text(todo.get("task"))
            owner = safe_text(todo.get("owner"))
            blocks.append({"block_type": 17, "todo": {"style": {"done": False}, "elements": [{"text_run": {"content": f"{task} (@{owner})"}}] }})
        blocks.append(empty_line())

    # 6. æ—¶é—´æˆ³ç« èŠ‚
    chapters = data.get("chapters", [])
    if chapters:
        blocks.append({"block_type": 4, "heading2": {"elements": [{"text_run": {"content": "â±ï¸ æ™ºèƒ½ç« èŠ‚"}}]}})
        for chap in chapters:
            time_str = safe_text(chap.get("time"))
            title_str = safe_text(chap.get("title"))
            blocks.append({"block_type": 12, "bullet": {"elements": [
                {"text_run": {"content": f"[{time_str}] {title_str}: ", "text_element_style": {"bold": True}}},
                {"text_run": {"content": safe_text(chap.get("summary")), "text_element_style": {"text_color": 7}}}
            ]}})

    return blocks

def push_blocks_to_feishu(doc_id, blocks):
    token = get_feishu_token()
    url = f"https://open.feishu.cn/open-apis/docx/v1/documents/{doc_id}/blocks/{doc_id}/children"
    headers = {"Authorization": f"Bearer {token}", "Content-Type": "application/json"}
    
    for i in range(0, len(blocks), 40):
        batch = blocks[i:i+40]
        try:
            res = requests.post(url, headers=headers, json={"children": batch}, timeout=15)
            if res.json().get("code") != 0:
                for block in batch:
                    requests.post(url, headers=headers, json={"children": [block]})
        except Exception:
            pass
    return f"https://bytedance.feishu.cn/docx/{doc_id}"

# ===================== 4. ã€æ ¸å¿ƒå¼ºåŒ–ã€‘AI ç”Ÿæˆä¸æ’ç‰ˆè§£æ =====================

@st.cache_resource
def load_model():
    return whisper.load_model("base")

def get_json_data(content):
    url = "https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation"
    headers = {"Authorization": f"Bearer {QWEN_API_KEY}", "Content-Type": "application/json"}
    
    prompt = f"""
    ä½ ç°åœ¨æ˜¯å•†ä¸šå’¨è¯¢é¡¾é—®ã€‚è¯·åˆ†æä¼šè®®é€å­—ç¨¿ï¼Œæå–å‡ºæ·±å±‚ä¿¡æ¯ï¼Œå¹¶ä¸¥æ ¼è¾“å‡º JSON æ ¼å¼ã€‚
    
    ã€è¾“å‡ºç»“æ„å¿…é¡»å¦‚ä¸‹ã€‘ï¼š
    {{
        "meta": {{
            "theme": "ä¼šè®®ä¸»é¢˜", "time": "æ¨æµ‹çš„æ—¶é—´", "participants": "å‘è¨€äºº"
        }},
        "quick_summary": [
            "ç”¨ä¸€å¥è¯æ€»ç»“ä¼šè®®è¾¾æˆçš„ç¬¬1ä¸ªæ ¸å¿ƒå…±è¯†",
            "ç”¨ä¸€å¥è¯æ€»ç»“ä¼šè®®è¾¾æˆçš„ç¬¬2ä¸ªæ ¸å¿ƒå…±è¯†"
        ],
        "mermaid_code": "graph TD\\nA[æ ¸å¿ƒä¸»é¢˜] --> B(å…³é”®è®®é¢˜)\\nB --> C(å¾—å‡ºçš„ç»“è®º)\\nA --> D(å…¶ä»–è¦ç‚¹)",
        "topics": [
            {{
                "title": "è®®é¢˜åç§°",
                "details": ["ç»†èŠ‚1(ä¿ç•™æ•°æ®)", "ç»†èŠ‚2"],
                "conclusion": "è¯¥è®®é¢˜å¾—å‡ºçš„ç»“è®º"
            }}
        ],
        "todos": [
            {{ "task": "å…·ä½“è¡ŒåŠ¨æŒ‡ä»¤", "owner": "è´Ÿè´£äºº" }}
        ],
        "chapters": [
            {{ "time": "00:00:00", "title": "èŠ‚ç‚¹ä¸»é¢˜", "summary": "ç®€è¦è¯´æ˜" }}
        ]
    }}
    
    ã€é˜²å´©æºƒè­¦å‘Šã€‘ï¼š
    1. mermaid_code å¿…é¡»æ˜¯ä¸€æ®µæç®€çš„ã€åˆæ³•çš„ Mermaid æµç¨‹å›¾ä»£ç ã€‚èŠ‚ç‚¹å†…ä¸è¦ç”¨å†’å·ã€å¤§æ‹¬å·ã€ç‰¹æ®Šç¬¦å·ï¼æ¢è¡Œè¯·å†™ä¸ºçœŸæ­£çš„ \\nï¼
    
    åŸæ–‡å†…å®¹ï¼š{content[:25000]}
    """
    
    try:
        res = requests.post(url, headers=headers, json={"model": "qwen-max", "input": {"messages": [{"role": "user", "content": prompt}]}}, timeout=180)
        res_data = res.json()
        
        if "output" not in res_data: return None
            
        text = res_data["output"]["text"]
        match = re.search(r'\{.*\}', text, re.DOTALL)
        
        if match:
            return json.loads(match.group(0), strict=False)
        return None
    except Exception as e:
        st.error(f"âŒ å‘ç”ŸæœªçŸ¥ç½‘ç»œé”™è¯¯: {e}")
        return None

# ===================== 5. ä¸»æ§ UI =====================

st.title("ğŸ“ˆ é£ä¹¦æ™ºèƒ½çºªè¦ï¼šçœŸå®å›¾æ–‡æ¶æ„ç‰ˆ")
st.info("å·²å½»åº•ä¿®å¤é£ä¹¦åª’ä½“ä¸Šä¼ é‰´æƒï¼Œæµç¨‹å›¾/æ€ç»´å¯¼å›¾ç°åœ¨å°†ä»¥é«˜æ¸…å›¾ç‰‡å½¢å¼æŒ‚è½½ï¼")

uploaded_file = st.file_uploader("è¯·ä¸Šä¼ ä¼šè®®æ–‡ä»¶ (TXT/Audio)", type=["mp3", "wav", "m4a", "txt"])

if uploaded_file and st.button("ğŸš€ ç”Ÿæˆä¸‡èƒ½å›¾æ–‡çºªè¦", type="primary"):
    with st.status("æ­£åœ¨å¯åŠ¨å›¾æ–‡æ¶æ„å¼•æ“...", expanded=True) as status:
        
        status.write("1ï¸âƒ£ è§£æè¾“å…¥æ–‡ä»¶...")
        if uploaded_file.name.endswith('.txt'):
            raw_text = uploaded_file.read().decode("utf-8")
        else:
            status.write("æ­£åœ¨æå–å¸¦æ—¶é—´æˆ³çš„è¯­éŸ³åˆ‡ç‰‡...")
            model = load_model()
            temp_path = f"temp_{uploaded_file.name}"
            with open(temp_path, "wb") as f: f.write(uploaded_file.getbuffer())
            
            result = model.transcribe(temp_path, language="zh")
            raw_text = ""
            for seg in result["segments"]:
                raw_text += f"[{int(seg['start']//60):02d}:{int(seg['start']%60):02d}] {seg['text']}\n"
            os.remove(temp_path)
            
        status.write("2ï¸âƒ£ AI æ­£åœ¨è¿›è¡Œè®®é¢˜ä¸‹é’»ä¸é€»è¾‘æ¶æ„æç‚¼ (å¯èƒ½éœ€è¦ 1-2 åˆ†é’Ÿ)...")
        json_data = get_json_data(raw_text)
        
        if json_data:
            status.write("3ï¸âƒ£ å»ºç«‹äº‘ç«¯é€šé“...")
            doc_id = create_feishu_doc(json_data.get('meta', {}).get('theme', 'ä¸‡èƒ½å›¾æ–‡çºªè¦'))
            
            if doc_id:
                status.write("4ï¸âƒ£ æ­£åœ¨æ¸²æŸ“é«˜æ¸…æ¶æ„å›¾ç‰‡å¹¶ä¸Šä¼ é£ä¹¦åª’ä½“åº“...")
                mermaid_code = json_data.get("mermaid_code")
                # ä¿®å¤æ ¸å¿ƒï¼šè¿™é‡Œå°† doc_id ä¼ è¿›å»äº†ï¼
                diagram_token = upload_diagram_to_feishu(doc_id, mermaid_code) if mermaid_code else None
                
                if diagram_token:
                    status.write("âœ”ï¸ æ¶æ„å›¾æ¸²æŸ“æˆåŠŸï¼Œå·²æˆåŠŸæŒ‚è½½åˆ°äº‘æ–‡æ¡£ï¼")
                else:
                    status.write("âš ï¸ å›¾ç‰‡æ¸²æŸ“è·³è¿‡ï¼Œä»…ç”Ÿæˆå›¾æ–‡æ’ç‰ˆã€‚")
                
                status.write("5ï¸âƒ£ æ³¨å…¥é€šç”¨å®‰å…¨æ’ç‰ˆä¸åŸå£°åˆ‡ç‰‡...")
                blocks = build_universal_blocks(json_data, diagram_token)
                doc_url = push_blocks_to_feishu(doc_id, blocks)
                
                if doc_url:
                    status.update(label="âœ… åŸç”Ÿé£ä¹¦å›¾æ–‡çºªè¦ç”ŸæˆæˆåŠŸï¼", state="complete")
                    st.markdown(f"""
                    <div style="background:#f0f2f5; padding:30px; border-radius:15px; text-align:center;">
                        <h2 style="color:#1f2329;">ğŸ‰ æ‚¨çš„ä¸“å±å›¾æ–‡çœ‹æ¿å·²å°±ç»ª</h2>
                        <a href="{doc_url}" target="_blank" style="background:#3370ff; color:white; padding:15px 40px; text-decoration:none; border-radius:8px; font-weight:bold; font-size:18px; display:inline-block; margin-top:10px;">
                            ğŸš€ ç«‹å³æ£€é˜…éœ‡æ’¼çš„æ’ç‰ˆæ•ˆæœ
                        </a>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    # åŒä¿é™©ï¼šå³ä½¿å›¾ç‰‡æ²¡æ’è¿›é£ä¹¦ï¼Œé¡µé¢ä¸‹æ–¹ä¹Ÿä¼šå±•ç¤ºåº•å±‚ä»£ç 
                    if mermaid_code:
                        with st.expander("ğŸ” é™„ï¼šAI ç”Ÿæˆçš„åº•å±‚æ¶æ„ä»£ç  (Mermaid)"):
                            st.code(mermaid_code, language="mermaid")
                            
                else:
                    status.update(label="âŒ å†™å…¥å¼‚å¸¸ï¼Œè¯·æ£€æŸ¥æ—¥å¿—", state="error")
            else:
                status.update(label="âŒ æ–‡æ¡£åˆ›å»ºå¤±è´¥", state="error")
        else:
            status.update(label="âŒ è¿›ç¨‹ä¸­æ­¢ï¼Œå¤§æ¨¡å‹æ•°æ®è·å–å¼‚å¸¸", state="error")
