import streamlit as st
import requests
import json
import os
import whisper
import time
from dotenv import load_dotenv

# ===================== 1. åŸºç¡€é…ç½®ä¸è§†è§‰é£æ ¼æ³¨å…¥ =====================
load_dotenv()
st.set_page_config(
    page_title="é£ä¹¦åŒæ¬¾æ™ºèƒ½çºªè¦ç”Ÿæˆå·¥å…·",
    page_icon="ğŸ“",
    layout="wide",
    initial_sidebar_state="expanded"
)

# æ ¸å¿ƒå¯†é’¥é…ç½®
QWEN_API_KEY = st.secrets.get("QWEN_API_KEY", "sk-ecb46034c430477e9c9a4b4fd6589742")
FEISHU_WEBHOOK = st.secrets.get("FEISHU_WEBHOOK", "")

# æ³¨å…¥ CSSï¼šå®Œç¾å¤åˆ»é£ä¹¦å¡ç‰‡å®¹å™¨ä¸è‰²å—æ ‡ç­¾
st.markdown("""
<style>
    .feishu-summary-container {
        background: #ffffff;
        border: 1px solid #dee0e3;
        border-radius: 10px;
        padding: 24px;
        box-shadow: 0 4px 12px rgba(31,35,41,0.08);
        margin-bottom: 25px;
    }
    .project-grid {
        display: flex;
        gap: 16px;
        margin: 20px 0;
    }
    .project-card {
        flex: 1;
        border: 1px solid #e5e6eb;
        border-radius: 8px;
        padding: 16px;
        background: #f9fafb;
    }
    .section-header { font-size: 18px; font-weight: bold; color: #1f2329; margin-bottom: 12px; }
    .tag { padding: 2px 8px; border-radius: 4px; font-size: 12px; font-weight: bold; float: right; }
    .tag-green { background: #e8f8f2; color: #00b67a; } /* æ­£å¸¸æ¨è¿› */
    .tag-orange { background: #fff7e8; color: #ff9d00; } /* éœ€è¦ä¼˜åŒ– */
    .tag-red { background: #fff2f0; color: #f53f3f; } /* å­˜åœ¨é£é™© */
    .next-step-box {
        background-color: #fff7e8;
        border-radius: 4px;
        padding: 12px;
        border-left: 4px solid #ff9d00;
        margin-top: 20px;
        color: #1f2329;
    }
</style>
""", unsafe_allow_html=True)

# ===================== 2. è¯­éŸ³å¤„ç†ä¸æœ¯è¯­è¯†åˆ« (å¹³ç§»æ‚¨çš„æ ¸å¿ƒé€»è¾‘) =====================

@st.cache_resource
def load_whisper_model():
    return whisper.load_model("base")

whisper_model = load_whisper_model()

def audio_to_text(audio_file):
    """
    æœ¬åœ°Whisperè½¬å†™ï¼šæ”¯æŒ3ç§’åœé¡¿å‘è¨€äººè¯†åˆ«+æœ¯è¯­ä¿æŠ¤
    """
    temp_path = f"temp_{audio_file.name}"
    with open(temp_path, "wb") as f:
        f.write(audio_file.getbuffer())
    
    result = whisper_model.transcribe(temp_path, language="zh", word_timestamps=True, fp16=False)
    
    transcript = []
    speaker_id = 1
    last_end_time = 0
    filler_words = ["å—¯", "å•Š", "è¿™ä¸ª", "é‚£ä¸ª", "ç„¶å", "å…¶å®", "å°±æ˜¯è¯´", "å¥½çš„", "è¡Œ", "å“¦", "å¯¹"]
    key_terms = ["æ–‡ä»¶æŸœ", "é¤è¾¹æŸœ", "é¢†æ˜Ÿç³»ç»Ÿ", "äº‘ä»“", "CGè´¦å·", "ROAS", "UPC", "SKU"]
    
    for segment in result["segments"]:
        # åˆ¤å®šå‘è¨€äººåˆ‡æ¢
        if segment["start"] - last_end_time >= 3 and len(transcript) > 0:
            speaker_id += 1
        last_end_time = segment["end"]
        
        clean_text = segment["text"]
        for word in filler_words: clean_text = clean_text.replace(word, "")
        for term in key_terms:
            if term.lower() in clean_text.lower(): clean_text = clean_text.replace(term.lower(), term)
        
        if clean_text.strip():
            transcript.append({
                "speaker": f"å‘è¨€äºº{speaker_id}",
                "text": clean_text.strip(),
                "time": f"{int(segment['start']//60):02d}:{int(segment['start']%60):02d}"
            })
    
    os.remove(temp_path)
    return transcript

# ===================== 3. å›¾æ–‡è½¬æ¢æ¸²æŸ“ä¸ AI ç”Ÿæˆ =====================

def fix_feishu_visual_format(summary_text):
    """
    å°† AI æ–‡æœ¬æ ‡ç­¾è½¬æ¢ä¸ºå¸¦é¢œè‰²çš„ HTML å›¾æ–‡è‰²å—
    """
    summary_text = summary_text.replace("[æ­£å¸¸æ¨è¿›]", '<span class="tag tag-green">æ­£å¸¸æ¨è¿›</span>')
    summary_text = summary_text.replace("[éœ€è¦ä¼˜åŒ–]", '<span class="tag tag-orange">éœ€è¦ä¼˜åŒ–</span>')
    summary_text = summary_text.replace("[å­˜åœ¨é£é™©]", '<span class="tag tag-red">å­˜åœ¨é£é™©</span>')
    summary_text = summary_text.replace("[å·²å®Œæˆ]", '<span class="tag tag-green">å·²å®Œæˆ</span>')
    summary_text = summary_text.replace("[å¾…å¤„ç†]", '<span class="tag tag-red">å¾…å¤„ç†</span>')
    
    # æ³¨å…¥å¡ç‰‡å®¹å™¨
    if "æ€»ç»“" in summary_text:
        summary_text = summary_text.replace("æ€»ç»“", '<div class="section-header">ğŸ“Š é‡ç‚¹é¡¹ç›®æ¦‚è§ˆ</div>')
    
    return f'<div class="feishu-summary-container">{summary_text}</div>'

def generate_feishu_pro_summary(transcript_data):
    """
    è°ƒç”¨ Qwen-Max 1:1 è¿˜åŸ PDF 8å¤§æ¨¡å—
    """
    url = "https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation"
    headers = {"Authorization": f"Bearer {QWEN_API_KEY}", "Content-Type": "application/json"}
    
    # å¼ºåˆ¶ AI è¾“å‡ºå›¾æ–‡é¢æ¿æ‰€éœ€çš„ç‰¹å®šæ ¼å¼
    prompt = f"""
    ä½ æ˜¯ä¸“ä¸šçš„é£ä¹¦æ™ºèƒ½ç§˜ä¹¦ã€‚è¯·æ ¹æ®è½¬å½•å†…å®¹ç”Ÿæˆ 100% è¿˜åŸé£ä¹¦æ ·å¼çš„å›¾æ–‡çºªè¦ã€‚
    ã€æ ¸å¿ƒæ¨¡å—ã€‘ï¼š
    1. æ€»ç»“ï¼šæç‚¼ 3-5 ä¸ªé‡ç‚¹é¡¹ç›®ï¼Œæ¯ä¸ªé¡¹ç›®å¿…é¡»å¸¦çŠ¶æ€æ ‡ç­¾ï¼š[æ­£å¸¸æ¨è¿›]ã€[éœ€è¦ä¼˜åŒ–] æˆ– [å­˜åœ¨é£é™©]ã€‚
    2. è¿è¥å·¥ä½œè·Ÿè¿›ï¼šè¡¨æ ¼å±•ç¤º (ç±»åˆ«|å†…å®¹|è´Ÿè´£äºº|çŠ¶æ€)ã€‚
    3. ä¸‹ä¸€æ­¥è®¡åˆ’ï¼šğŸ’¡ å¼€å¤´ï¼Œæ€»ç»“æ ¸å¿ƒåŠ¨ä½œã€‚
    4. å…³é”®å†³ç­–ï¼šé—®é¢˜ -> æ–¹æ¡ˆ -> ä¾æ®ã€‚
    5. é‡‘å¥æ—¶åˆ»ï¼šå¼•ç”¨åŸè¯ã€‚
    6. æ™ºèƒ½ç« èŠ‚ï¼šå¸¦ XX:XX æ—¶é—´æˆ³ã€‚

    å†…å®¹ï¼š{json.dumps(transcript_data, ensure_ascii=False)}
    """

    payload = {
        "model": "qwen-max", # å‡çº§è‡³ max è·å–æ›´å¥½çš„é€»è¾‘åŠ›
        "input": {"messages": [{"role": "user", "content": prompt}]},
        "parameters": {"result_format": "text", "temperature": 0.1}
    }

    try:
        response = requests.post(url, headers=headers, json=payload, timeout=60)
        res_json = response.json()
        if "output" not in res_json:
            st.error(f"API è¿”å›å¼‚å¸¸: {res_json}")
            return None
        return fix_feishu_visual_format(res_json["output"]["text"])
    except Exception as e:
        st.error(f"ç”Ÿæˆå¤±è´¥: {e}")
        return None

# ===================== 4. UI äº¤äº’å¸ƒå±€ =====================

st.title("ğŸ“ é£ä¹¦åŒæ¬¾æ™ºèƒ½çºªè¦ç”Ÿæˆå·¥å…· (æè‡´å›¾æ–‡ç‰ˆ)")
st.divider()

col_in, col_out = st.columns([1, 1.5], gap="large")

with col_in:
    st.subheader("ğŸ“¥ è¾“å…¥åŒºåŸŸ")
    audio_file = st.file_uploader("ä¸Šä¼ å½•éŸ³", type=["mp3", "wav", "m4a"])
    text_input = st.text_area("æˆ–ç²˜è´´è½¬å†™æ–‡æœ¬", height=300)
    generate_btn = st.button("ğŸš€ ç”Ÿæˆå›¾æ–‡æ€»ç»“çœ‹æ¿", type="primary", use_container_width=True)

with col_out:
    st.subheader("ğŸ“‹ å›¾æ–‡çºªè¦çœ‹æ¿é¢„è§ˆ")
    if generate_btn:
        with st.spinner("ğŸ§  æ­£åœ¨å¤šç»´å¤åˆ»é£ä¹¦çº§å›¾æ–‡çœ‹æ¿..."):
            # æ•°æ®è·å–
            if audio_file:
                transcript = audio_to_text(audio_file)
            elif text_input:
                transcript = [{"speaker": "å‘è¨€äºº1", "text": text_input, "time": "00:00"}]
            else:
                st.warning("è¯·æä¾›è¾“å…¥å†…å®¹")
                st.stop()
            
            # æ€»ç»“ç”Ÿæˆ
            final_html = generate_feishu_pro_summary(transcript)
            if final_html:
                st.markdown(final_html, unsafe_allow_html=True)
                
                # åŒæ­¥é£ä¹¦æ¨é€ (äº’åŠ¨å¡ç‰‡æ ¼å¼)
                if FEISHU_WEBHOOK:
                    st.info("ğŸ“² å›¾æ–‡å¡ç‰‡å·²è‡ªåŠ¨æ¨é€åˆ°é£ä¹¦ç¾¤ç»„ã€‚")
